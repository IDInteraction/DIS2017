@inproceedings{Apaolaza2016,
abstract = {Video data of people interacting with devices contains rich information about human behaviour that can be used to design or improve user experience. As a first step, it must be interpreted -- or coded -- into a form that can be analyzed systematically. The coding process is currently performed manually, and it can be slow and difficult, and biased by subjectivity. This is particularly problematic when trying to obtain data that should be objective, such as the movements of a user in relation to a device. We describe Automated Behavioural Coding (ABC), an open source object tracking technique designed to log user and device movements, and then output positional data that can be used to model interaction. We validate the technique in a study of dual screen TV viewing, and show that the ABC tool is able to correctly classify the direction of gaze to the TV or tablet up to 95$\backslash${\%} of the time, in a fraction of the time it takes to capture this data manually.},
author = {Apaolaza, Aitor and Haines, Robert and Aizpurua, Amaia and Brown, Andy and Evans, Michael and Jolly, Stephen and Harper, Simon and Jay, Caroline},
file = {:home/zzalsdme/Downloads/abc.pdf:pdf},
booktitle = {In: Extended Abstracts on Human Factors in Computing Systems: CHI'16; 07 May 2016-12 May 2016},
keywords = {Behavioural coding,object tracking,reproducible methods,television,visual attention},
publisher = {ACM},
title = {{ABC: Using Object Tracking to Automate Behavioural Coding}},
year = {2016}
}

@inproceedings{Baltrusaitis2016,
  author	=	{Tadas Baltru\v{s}aitis and Peter Robinson and Louis-Philippe Morency},
  title		=	{OpenFace: an open source facial behavior analysis toolkit},
  booktitle	=	{IEEE Winter Conference on Applications of Computer Vision},
  year		=	2016,
}

@inproceedings{Nebehay2015CVPR,
    author = {Nebehay, Georg and Pflugfelder, Roman},
    booktitle = {Computer Vision and Pattern Recognition},
    month = jun,
    publisher = {IEEE},
    title = {Clustering of {Static-Adaptive} Correspondences for Deformable Object Tracking},
    year = {2015}
}


  @Manual{Knitr,
    title = {knitr: A General-Purpose Package for Dynamic Report
      Generation in R},
    author = {Yihui Xie},
    year = {2016},
    note = {R package version 1.15.1},
    url = {http://yihui.name/knitr/},
  }
  
@Misc{Metawear,
  author = {Mbientlab}, 
  note = {Retrieved 1 March 2017 from \url{https://mbientlab.com/sensors/}},
  year = 2016}
  
  @inproceedings{ELAN,
  author = {Sloetjes, H and Wittenburg, P},
  title = {Annotation by category---ELAN and ISO DCR},
  booktitle = {Proceedings of the 6th International Conference on Language Resources and Evaluation },
  year = 2008,
  url = {http://tla.mpi.nl/tools/tla-tools/elan/}
  }
  
@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}